{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "1\n",
      "tensor([[[-0.8448, -1.4859, -2.6522, -2.9047, -1.5197]]])\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "torch.Size([5, 5])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributions as td\n",
    "\n",
    "def all_one_hot_combinations(N, K):\n",
    "    # N is number of 1's in the hot vector\n",
    "    return np.eye(K).take(np.reshape(np.indices([K] * N), [N, -1]).T, axis=0).reshape(-1, N * K)  # [K**N, N*K]\n",
    "\n",
    "N = 1\n",
    "K = 5\n",
    "\n",
    "val = all_one_hot_combinations(N, K)\n",
    "print(val)\n",
    "z_dim = N*K\n",
    "\n",
    "h = torch.randn(N*K)\n",
    "logits_separated = torch.reshape(h, (-1, N, K))\n",
    "logits_separated_mean_zero = logits_separated - torch.mean(logits_separated, dim=-1, keepdim=True)\n",
    "dist = td.OneHotCategorical(logits=logits_separated_mean_zero)\n",
    "dist.sample()\n",
    "bs = dist.probs.size()[0]\n",
    "print(bs)\n",
    "\n",
    "num_components = N*K\n",
    "num_samples = 1\n",
    "z_NK = torch.from_numpy(all_one_hot_combinations(N, K)).float().repeat(num_samples, bs)\n",
    "z_stacked = torch.reshape(z_NK, (num_samples * num_components, -1, N*K))\n",
    "z = torch.reshape(z_stacked, (-1, z_dim))\n",
    "\n",
    "\n",
    "print(dist.logits.repeat(1, 1, 1))\n",
    "\n",
    "# k is number of samples - we just have 1 sample\n",
    "# number of components is N*K???\n",
    "\n",
    "# why are we reshaping to be [num_samples * num_components, -1, N*K]?\n",
    "# because we want to sample from the distribution, and we want to sample from each component of the distribution\n",
    "\n",
    "print(z_NK)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('prisoner_auto')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0c3bfbc0528239c32ebf5b583237c33afb2ab3d4f242283158514eeade34da9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
