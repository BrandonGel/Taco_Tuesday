{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions import Categorical\n",
    "from torch.distributions.gumbel import Gumbel\n",
    "\n",
    "def sample_mixture_gumbel(pi, mu, sigma, temp=0.1):\n",
    "    \"\"\" \n",
    "    \n",
    "    Given a mixture of gaussians, sample from the mixture in a way that we can backpropagate through\n",
    "\n",
    "    pi: (B, G)\n",
    "    mu: (B, G, D)\n",
    "    sigma: (B, G, D)\n",
    "\n",
    "    First, sample categorically from the mixture pi with gumbel softmax.\n",
    "    Then, sample from the corresponding gaussian by multiplying and adding with mean and std.\n",
    "\n",
    "    Returns shape of (B, D) where we have batch size and dimension of gaussian\n",
    "\n",
    "    \"\"\"\n",
    "    m = Gumbel(torch.zeros_like(pi), torch.ones_like(pi))\n",
    "    g = m.sample()\n",
    "    gumbel_softmax = torch.softmax((torch.log(pi) + g)/temp, dim=-1) # (B, num_gaussians)\n",
    "\n",
    "    eps = torch.randn_like(sigma)\n",
    "    samples = mu + (eps * sigma)\n",
    "\n",
    "    print(samples.shape)\n",
    "    print(gumbel_softmax.shape)\n",
    "\n",
    "\n",
    "    print(samples)\n",
    "    print(gumbel_softmax)\n",
    "    gumbel_weighted = torch.einsum('bgd,bg->bd', [samples, gumbel_softmax])\n",
    "    print(gumbel_weighted)\n",
    "    print(gumbel_weighted.shape)\n",
    "    return gumbel_softmax\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2])\n",
      "torch.Size([2, 3])\n",
      "tensor([[[ 1.0011, -1.0004],\n",
      "         [ 1.9999, -1.9996],\n",
      "         [ 3.0007, -2.9999]],\n",
      "\n",
      "        [[ 1.0003, -0.9988],\n",
      "         [ 1.9992, -2.0002],\n",
      "         [ 3.0006, -2.9991]]])\n",
      "tensor([[1.0000e+00, 8.0938e-08, 4.2895e-07],\n",
      "        [1.0000e+00, 3.4458e-20, 2.4563e-18]])\n",
      "tensor([[ 1.0011, -1.0005],\n",
      "        [ 1.0003, -0.9988]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "pi = torch.tensor([[0.05, 0.5, 0.7], \n",
    "                   [0.7, 0.1, 0.2]]) # B, n_gaussians\n",
    "\n",
    "# pi = torch.tensor([[0.05, 0.95], \n",
    "#                    [0.5, 0.5]]) # B, n_gaussians\n",
    "# mu = torch.tensor([[[1.0], [2.0], [3]], [[1.0], [2.0], [3.0]]]) # B x n_gaussians x 1\n",
    "# sigma = torch.tensor([[[1.0], [2.0], [3.0]], [[1.0], [2.0], [3.0]]])\n",
    "\n",
    "mu = torch.tensor([[[1.0, -1.0], [2.0, -2.0], [3, -3]], [[1.0, -1.0], [2.0, -2.0], [3, -3]]]) # B x n_gaussians x 1\n",
    "# sigma = torch.tensor([[[1.0, -1.0], [1.0, -1.0], [1.0, -1.0]], [[1.0, -1.0], [1.0, -1.0], [1.0, -1.0]]])\n",
    "sigma = torch.ones((2, 3, 2)) * 0.001\n",
    "\n",
    "# print(pi.shape, mu.shape, sigma.shape)\n",
    "\n",
    "a = torch.zeros(2)\n",
    "for i in range(1):\n",
    "    res = sample_mixture_gumbel(pi, mu, sigma)\n",
    "    # print(res.shape)\n",
    "    b = torch.argmax(res, dim=1)\n",
    "    a = a + b\n",
    "    # print(b)\n",
    "\n",
    "# print(a)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0c3bfbc0528239c32ebf5b583237c33afb2ab3d4f242283158514eeade34da9"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('prisoner_auto')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
